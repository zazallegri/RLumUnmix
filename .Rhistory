## Read and prepare data for unmixing
output <- Prepare_data_for_tracer_selection(data_path)
sgeo <- output$sgeo
mgeo <- output$mgeo
Population_fraction <- output$Population_fraction
source_list <- output$source_list
stacked_df_OG <- output$stacked_df_OG
print(sgeo)
print(mgeo)
## Perform consensus ranking
crgeo <- fingerPro::cr_ns(source=sgeo, mixture = mgeo, maxiter = 1000, seed = 1234567)
head(crgeo)
# ------------------- Perform unmixing using 2 - 10 tracers -------------------
for (nb_tracer in 2:10) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
score_threshold = 80,
nb_tracer = nb_tracer)
proportions_all <- rbind(proportions_all, output$proportions)
metrics_all <- rbind(metrics_all, output$metrics)
ratio_differences_all <- rbind(ratio_differences_all, output$ratio_differences)
}
data_path <- system.file("extdata", package="RLumUnmix")
# ------------------- Read and prepare data for unmixing -------------------
## Declare Data Frame for results
proportions_all <- data.frame()
ratio_differences_all <- data.frame()
metrics_all <- data.frame()
## Define expected ratios (if known) - also used as filename
pop_ratios_iteration <- c(0.25, 0.75)
# File corresponds to "stacked_df" from vignette "sandbox_2_synthetic_sources_preparations_for_unmixing".
filename <- paste0(as.character(pop_ratios_iteration[1]), "-", as.character(pop_ratios_iteration[2]))
data_path <- paste0(data_path, "/", filename, ".csv")
## Read and prepare data for unmixing
output <- Prepare_data_for_tracer_selection(data_path)
sgeo <- output$sgeo
mgeo <- output$mgeo
Population_fraction <- output$Population_fraction
source_list <- output$source_list
stacked_df_OG <- output$stacked_df_OG
print(sgeo)
print(mgeo)
## Perform consensus ranking
crgeo <- fingerPro::cr_ns(source=sgeo, mixture = mgeo, maxiter = 1000, seed = 1234567)
head(crgeo)
# ------------------- Perform unmixing using 2 - 10 tracers -------------------
for (nb_tracer in 2:10) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
score_threshold = 80,
nb_tracer = nb_tracer)
proportions_all <- rbind(proportions_all, output$proportions)
metrics_all <- rbind(metrics_all, output$metrics)
ratio_differences_all <- rbind(ratio_differences_all, output$ratio_differences)
}
devtools::load_all(".")
library(RLumUnmix)
library(fingerPro)
#library(magrittr)
#library(dplyr)
data_path <- system.file("extdata", package="RLumUnmix")
# ------------------- Read and prepare data for unmixing -------------------
## Declare Data Frame for results
proportions_all <- data.frame()
ratio_differences_all <- data.frame()
metrics_all <- data.frame()
## Define expected ratios (if known) - also used as filename
pop_ratios_iteration <- c(0.25, 0.75)
# File corresponds to "stacked_df" from vignette "sandbox_2_synthetic_sources_preparations_for_unmixing".
filename <- paste0(as.character(pop_ratios_iteration[1]), "-", as.character(pop_ratios_iteration[2]))
data_path <- paste0(data_path, "/", filename, ".csv")
## Read and prepare data for unmixing
output <- Prepare_data_for_tracer_selection(data_path)
sgeo <- output$sgeo
mgeo <- output$mgeo
Population_fraction <- output$Population_fraction
source_list <- output$source_list
stacked_df_OG <- output$stacked_df_OG
print(sgeo)
print(mgeo)
## Perform consensus ranking
crgeo <- fingerPro::cr_ns(source=sgeo, mixture = mgeo, maxiter = 1000, seed = 1234567)
head(crgeo)
# ------------------- Perform unmixing using 2 - 10 tracers -------------------
for (nb_tracer in 2:10) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
score_threshold = 80,
nb_tracer = nb_tracer)
proportions_all <- rbind(proportions_all, output$proportions)
metrics_all <- rbind(metrics_all, output$metrics)
ratio_differences_all <- rbind(ratio_differences_all, output$ratio_differences)
}
devtools::load_all(".")
library(RLumUnmix)
library(fingerPro)
#library(magrittr)
#library(dplyr)
data_path <- system.file("extdata", package="RLumUnmix")
# ------------------- Read and prepare data for unmixing -------------------
## Declare Data Frame for results
proportions_all <- data.frame()
ratio_differences_all <- data.frame()
metrics_all <- data.frame()
## Define expected ratios (if known) - also used as filename
pop_ratios_iteration <- c(0.25, 0.75)
# File corresponds to "stacked_df" from vignette "sandbox_2_synthetic_sources_preparations_for_unmixing".
filename <- paste0(as.character(pop_ratios_iteration[1]), "-", as.character(pop_ratios_iteration[2]))
data_path <- paste0(data_path, "/", filename, ".csv")
## Read and prepare data for unmixing
output <- Prepare_data_for_tracer_selection(data_path)
sgeo <- output$sgeo
mgeo <- output$mgeo
Population_fraction <- output$Population_fraction
source_list <- output$source_list
stacked_df_OG <- output$stacked_df_OG
print(sgeo)
print(mgeo)
## Perform consensus ranking
crgeo <- fingerPro::cr_ns(source=sgeo, mixture = mgeo, maxiter = 1000, seed = 1234567)
head(crgeo)
# ------------------- Perform unmixing using 2 - 10 tracers -------------------
for (nb_tracer in 2:10) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
score_threshold = 80,
nb_tracer = nb_tracer)
proportions_all <- rbind(proportions_all, output$proportions)
metrics_all <- rbind(metrics_all, output$metrics)
ratio_differences_all <- rbind(ratio_differences_all, output$ratio_differences)
}
devtools::load_all(".")
for (nb_tracer in 2:10) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
score_threshold = 80,
nb_tracer = nb_tracer)
proportions_all <- rbind(proportions_all, output$proportions)
metrics_all <- rbind(metrics_all, output$metrics)
ratio_differences_all <- rbind(ratio_differences_all, output$ratio_differences)
}
devtools::load_all(".")
for (nb_tracer in 2:10) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
score_threshold = 80,
nb_tracer = nb_tracer)
proportions_all <- rbind(proportions_all, output$proportions)
metrics_all <- rbind(metrics_all, output$metrics)
ratio_differences_all <- rbind(ratio_differences_all, output$ratio_differences)
}
## Get 3 best results (number of tracers used for unmixing that minimizes
## the Manhattan distance between the expected proportion and the median
## estimated proportion)
best_number_of_tracers <- head(metrics_all[order(metrics_all$Manhattan_dist_median), ], 3)$nb_tracer
best_metrics <- metrics_all[metrics_all$nb_tracer %in% best_number_of_tracers, ]
proportions_best <- data.frame()
ratio_differences_best <- data.frame()
metrics_best <- data.frame()
for (i in best_number_of_tracers) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
error_threshold = NULL,
score_threshold = best_metrics[best_metrics$nb_tracer == i, "score_threshold"],
nb_tracer = best_metrics[best_metrics$nb_tracer == i, "nb_tracer"],
tracer_pair = NULL)
proportions_best <- rbind(proportions_best, output$proportions)
metrics_best <- rbind(metrics_best, output$metrics)
ratio_differences_best <- rbind(ratio_differences_best, output$ratio_differences)
}
library(RLumUnmix)
library(fingerPro)
data_path <- system.file("extdata", package="RLumUnmix")
# ------------ Read and prepare data for unmixing ------------
## Declare Data Frame for results
proportions_all <- data.frame()
ratio_differences_all <- data.frame()
metrics_all <- data.frame()
## Define expected ratios (if known) - also used as filename
pop_ratios_iteration <- c(0.25, 0.5, 0.25)
## File corresponds to "stacked_df" from vignette "sandbox_3_synthetic_sources_preparations_for_unmixing".
filename <- paste0(as.character(pop_ratios_iteration[1]), "-", as.character(pop_ratios_iteration[2]), "-", as.character(pop_ratios_iteration[3]))
data_path <- paste0(data_path, "/", filename, ".csv")
## Read and prepare data for unmixing
output <- Prepare_data_for_tracer_selection(data_path)
sgeo <- output$sgeo
mgeo <- output$mgeo
Population_fraction <- output$Population_fraction
source_list <- output$source_list
stacked_df_OG <- output$stacked_df_OG
print(sgeo)
print(mgeo)
# ------------ Perform consensus ranking and "pairs" method describes in fingerPro pacakge ------------
crgeo <- cr_ns(source=sgeo, mixture = mgeo, maxiter = 1000, seed = 1234567)
head(crgeo)
pgeo <- pairs(sgeo, mgeo, iter = 1000, seed = 1234567)
head(pgeo)
# ------------  Take a look at pgeo and select the pairs to use for unmixing ------------
print(pgeo[(pgeo$cons == 1) & (order(pgeo$Dmax)), ])
pairs <- pgeo[(pgeo$cons == 1) & (pgeo$Dmax < 0.002), "id"]
# ------------ Perform unmixing using 2 - 10 tracers with pairs selected above ------------
for (pair in pairs) {
for (nb_tracer in 2:10) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
error_threshold = NULL,
score_threshold = 80,
nb_tracer = nb_tracer,
tracer_pair = pair)
proportions_all <- rbind(proportions_all, output$proportions)
metrics_all <- rbind(metrics_all, output$metrics)
ratio_differences_all <- rbind(ratio_differences_all, output$ratio_differences)
}
}
# ------------ Get best results (number of tracers used for unmixing that minimizes the Manhattan distance between the expected proportion and the median/mean estimated proportion) ------------
best_metrics <- metrics_all[(metrics_all$Manhattan_dist_mean <= 0.225) & (metrics_all$Manhattan_dist_median <= 0.235), ]
print(best_metrics)
proportions_best <- data.frame()
ratio_differences_best <- data.frame()
metrics_best <- data.frame()
for (i in seq_len(nrow(best_metrics))) {
output <- Complete_unmixing_routine(mgeo,
sgeo,
crgeo,
source_list,
Population_fraction,
filename,
error_threshold = NULL,
score_threshold = best_metrics[i, ]$score_threshold,
nb_tracer = best_metrics[i, ]$nb_tracer,
tracer_pair = best_metrics[i, ]$tracer_pair)
proportions_best <- rbind(proportions_best, output$proportions)
metrics_best <- rbind(metrics_best, output$metrics)
ratio_differences_best <- rbind(ratio_differences_best, output$ratio_differences)
}
# Results are clearly not as good as with two sources. More different proportions led to better results.
library(RLumUnmix)
library(sandbox)
library(dplyr)
data_path <- system.file("extdata", package="RLumUnmix")
# --------- Set parameters for each source population ---------
population_1_parameters <- .set_pars("Bailey2001")
data_path <- system.file("extdata", package="RLumUnmix")
# --------- Set parameters for each source population ---------
population_1_parameters <- .set_pars("Bailey2001")
data_path <- system.file("extdata", package="RLumUnmix")
# --------- Set parameters for each source population ---------
population_1_parameters <- RLumModel::.set_pars("Bailey2001")
population_1_parameters$N[2] <- population_1_parameters$N[2]*10
population_2_parameters <- RLumModel::.set_pars("Bailey2001")
population_2_parameters$N[1] <- 0
populations_parameters <- list(population_1_parameters, population_2_parameters)
# Setup lab dose rate + sequence
dose_rate = 0.1
sequence <- Get_sequence(file_path = paste0(data_path, "/SEQ_file.SEQ"),
lab_dose_rate = dose_rate)[1:8]
# Display parameters of population 1
print(populations_parameters[1])
# --------- Generate OSL-TL curves and retrive metrics ---------
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = population_1_parameters,
own_state_parameters = .set_pars("Bailey2001")$n)
library(RLumUnmix)
library(sandbox)
library(dplyr)
library(RLumModel)
data_path <- system.file("extdata", package="RLumUnmix")
# --------- Set parameters for each source population ---------
population_1_parameters <- RLumModel::.set_pars("Bailey2001")
population_1_parameters$N[2] <- population_1_parameters$N[2]*10
population_2_parameters <- RLumModel::.set_pars("Bailey2001")
population_2_parameters$N[1] <- 0
populations_parameters <- list(population_1_parameters, population_2_parameters)
# Setup lab dose rate + sequence
dose_rate = 0.1
sequence <- Get_sequence(file_path = paste0(data_path, "/SEQ_file.SEQ"),
lab_dose_rate = dose_rate)[1:8]
# Display parameters of population 1
print(populations_parameters[1])
# --------- Generate OSL-TL curves and retrive metrics ---------
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = population_1_parameters,
own_state_parameters = RLumModel::.set_pars("Bailey2001")$n)
metrics_1 <- Extract_OSL_TL_metrics_for_all_records(TL_hash = metrics_output$TL_metrics,
OSL_hash = metrics_output$OSL_metrics,
source_number = "S1",
records_to_extract_data_from = NULL)
# Source 2
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = population_2_parameters,
own_state_parameters = RLumModel::.set_pars("Bailey2001")$n)
metrics_2 <- Extract_OSL_TL_metrics_for_all_records(TL_hash = metrics_output$TL_metrics,
OSL_hash = metrics_output$OSL_metrics,
source_number = "S2",
records_to_extract_data_from = NULL)
# --------- Define population ratios in the mix sample + mix them using sandbox package ---------
pop_ratios_iteration <- c(0.25, 0.75)
## Create rulebook with population ratios and model parameters as rules in RuleBook
book_osl <- Make_luminescence_rulebook(populations_parameters = populations_parameters,
pop_ratios = pop_ratios_iteration)
# --------- Make samples of the mixtures (mix of source 1 and 2 with ratios defined in "pop_ratios_iteration") ---------
# Set seed for reproducibility
set.seed(2021)
# Take a sample
sample_osl <- sandbox::make_Sample(book=book_osl,
depth=2,
geometry="cylinder",
radius=0.0005,
length=0.001)
# Make aliquots of sample
sample_osl_aliquots <- sandbox::prepare_Aliquot(sample = sample_osl, diameter = 0.5)
# Make a single df from all aliquots
stacked_aliquots <- data.frame()
for (name in names(sample_osl_aliquots)) {
stacked_aliquots <- rbind(stacked_aliquots, sample_osl_aliquots[[name]])
}
# Generate signals based on parameters of mixture
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = prep_parameters_from_aliquot(aliquot = stacked_aliquots),
own_state_parameters = RLumModel::.set_pars("Bailey2001")$n)
metrics_mixed <- Extract_OSL_TL_metrics_for_all_records(TL_hash = metrics_output$TL_metrics,
OSL_hash = metrics_output$OSL_metrics,
source_number = "Mixed",
records_to_extract_data_from = NULL)
nb_pop_1 <- nrow(stacked_aliquots[stacked_aliquots$population == 1, c('population', 'osl_N1', 'osl_N2', 'osl_N3', 'osl_N4')])
nb_pop_2 <- nrow(stacked_aliquots[stacked_aliquots$population == 2, c('population', 'osl_N1', 'osl_N2', 'osl_N3', 'osl_N4')])
frac_pop_1 <- nb_pop_1/(nb_pop_1 + nb_pop_2)
frac_pop_2 <- nb_pop_2/(nb_pop_1 + nb_pop_2)
print(frac_pop_1)
print(frac_pop_2)
# --------- Prepare results for unmixing ---------
# Stack the Data Frames on top of each other, filling missing columns with NA
stacked_df <- dplyr::bind_rows(rbind(metrics_1, metrics_1), rbind(metrics_2, metrics_2), metrics_mixed)
# Replace NA values with 0
stacked_df[is.na(stacked_df)] <- 0
# fingerPro (used for unmixing) expects at least two different samples from each source. Artificially create two almost identical ones
stacked_df[2, -1] <- stacked_df[2, -1]*1.001
stacked_df[4, -1] <- stacked_df[4, -1]*1.001
# Add expected population fractions (stemming from the mixing of both sources through sandbox)
stacked_df$Pop_fraction <- c(rep(frac_pop_1, 2), rep(frac_pop_2, 2), rep(NaN, 1))
print(stacked_df)
# Save the Data Frame
#filename <- paste0(as.character(pop_ratios_iteration[1]),"-", as.character(pop_ratios_iteration[2]))
#write.csv(stacked_df, file = paste0(data_path, "/", filename, ".csv"))
# --------- If you want to make a single df for each aliquot, change the above code accordingly: ---------
## make aliquots of sample
sample_osl_aliquots <- prepare_Aliquot(sample = sample_osl, diameter = 1.6)
print(glue("Total number of aliquots: {length(names(sample_osl_aliquots))}"))
metrics_mixed_all <- data.frame()
for (name in names(sample_osl_aliquots)) {
stacked_aliquots <- sample_osl_aliquots[[name]]
print(glue("Aliquot {name}"))
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = prep_parameters_from_aliquot(aliquot = stacked_aliquots),
own_state_parameters = RLumModel::.set_pars("Bailey2001")$n)
nb_pop_1 <- nrow(stacked_aliquots[stacked_aliquots$population == 1, c('population', 'osl_N1', 'osl_N2', 'osl_N3', 'osl_N4')])
nb_pop_2 <- nrow(stacked_aliquots[stacked_aliquots$population == 2, c('population', 'osl_N1', 'osl_N2', 'osl_N3', 'osl_N4')])
frac_pop_1 <- nb_pop_1/(nb_pop_1 + nb_pop_2)
frac_pop_2 <- nb_pop_2/(nb_pop_1 + nb_pop_2)
metrics_mixed <- Single_record_TL_OSL_metrics_df(TL_hash = metrics_output$TL_metrics,
OSL_hash = metrics_output$OSL_metrics,
record_num = keys(metrics_output$TL_metrics)[[1]])
metrics_mixed <- cbind("sources" = rep("Mixed", nrow(metrics_mixed)), metrics_mixed)
metrics_mixed_all <- rbind(metrics_mixed_all, metrics_mixed)
}
library(RLumUnmix)
library(sandbox)
library(dplyr)
library(RLumModel)
data_path <- system.file("extdata", package="RLumUnmix")
# ---------- Set parameters for each source population ----------
population_1_parameters <- RLumModel::.set_pars("Bailey2001")
population_1_parameters$N[2] <- population_1_parameters$N[2]*10
population_2_parameters <- RLumModel::.set_pars("Bailey2001")
population_2_parameters$N[1] <- 0
population_3_parameters <- RLumModel::.set_pars("Bailey2001")
populations_parameters <- list(population_1_parameters, population_2_parameters, population_3_parameters)
# Setup lab dose rate + sequence
dose_rate = 0.1
sequence <- Get_sequence(file_path = paste0(data_path, "/SEQ_file.SEQ"),
lab_dose_rate = dose_rate)[1:8]
# Display parameters of population 1
print(populations_parameters[1])
# --------- Generate OSL-TL curves and retrieve metrics -----------
# Source 1
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = population_1_parameters,
own_state_parameters = RLumModel::.set_pars("Bailey2001")$n)
metrics_1 <- Extract_OSL_TL_metrics_for_all_records(TL_hash = metrics_output$TL_metrics,
OSL_hash = metrics_output$OSL_metrics,
source_number = "S1",
records_to_extract_data_from = NULL)
# Source 2
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = population_2_parameters,
own_state_parameters = RLumModel::.set_pars("Bailey2001")$n)
metrics_2 <- Extract_OSL_TL_metrics_for_all_records(TL_hash = metrics_output$TL_metrics,
OSL_hash = metrics_output$OSL_metrics,
source_number = "S2",
records_to_extract_data_from = NULL)
# Source 3
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = population_3_parameters,
own_state_parameters = RLumModel::.set_pars("Bailey2001")$n)
metrics_3 <- Extract_OSL_TL_metrics_for_all_records(TL_hash = metrics_output$TL_metrics,
OSL_hash = metrics_output$OSL_metrics,
source_number = "S3",
records_to_extract_data_from = NULL)
# ---------- Define population ratios in the mix sample + mix them using sandbox package ----------
pop_ratios_iteration <- c(0.25, 0.5, 0.25)
## Create rulebook with population ratios and model parameters as rules in RuleBook
book_osl <- Make_luminescence_rulebook(populations_parameters = populations_parameters,
pop_ratios = pop_ratios_iteration)
# ---------- Make samples of the mixtures (mix of source 1 and 2 with ratios defined in "pop_ratios_iteration") ----------
# Set seed for reproducibility
set.seed(2021)
# Take a sample
sample_osl <- sandbox::make_Sample(book=book_osl,
depth=2,
geometry="cylinder",
radius=0.0005,
length=0.001)
# Make aliquots of sample
sample_osl_aliquots <- sandbox::prepare_Aliquot(sample = sample_osl, diameter = 0.5)
# Make a single df from all aliquots
stacked_aliquots <- data.frame()
for (name in names(sample_osl_aliquots)) {
stacked_aliquots <- rbind(stacked_aliquots, sample_osl_aliquots[[name]])
}
# Generate signals based on parameters of mixture
metrics_output <- Make_custom_model_and_retrieve_OSL_TL_metrics(
sequence,
dose_rate,
own_parameters = prep_parameters_from_aliquot(aliquot = stacked_aliquots),
own_state_parameters = .set_pars("Bailey2001")$n)
# Example of using a single record (instead of all of them as done in vignette "Preparation of 2 synthetic sources for unmixing using sandbox")
metrics_mixed <- Extract_OSL_TL_metrics_for_all_records(TL_hash = metrics_output$TL_metrics,
OSL_hash = metrics_output$OSL_metrics,
source_number = "Mixed",
records_to_extract_data_from = "Record_1")
nb_pop_1 <- nrow(stacked_aliquots[stacked_aliquots$population == 1, c('population', 'osl_N1', 'osl_N2', 'osl_N3', 'osl_N4')])
nb_pop_2 <- nrow(stacked_aliquots[stacked_aliquots$population == 2, c('population', 'osl_N1', 'osl_N2', 'osl_N3', 'osl_N4')])
nb_pop_3 <- nrow(stacked_aliquots[stacked_aliquots$population == 3, c('population', 'osl_N1', 'osl_N2', 'osl_N3', 'osl_N4')])
frac_pop_1 <- nb_pop_1/(nb_pop_1 + nb_pop_2 + nb_pop_3)
frac_pop_2 <- nb_pop_2/(nb_pop_1 + nb_pop_2 + nb_pop_3)
frac_pop_3 <- nb_pop_3/(nb_pop_1 + nb_pop_2 + nb_pop_3)
print(frac_pop_1)
print(frac_pop_2)
print(frac_pop_3)
# ----------- Prepare results for unmixing ----------
# Stack the Data Frames on top of each other, filling missing columns with NA
stacked_df <- dplyr::bind_rows(rbind(metrics_1, metrics_1), rbind(metrics_2, metrics_2), rbind(metrics_3, metrics_3), metrics_mixed)
# Replace NA values with 0
stacked_df[is.na(stacked_df)] <- 0
# fingerPro (used for unmixing) expects at least two different samples from each source. Artificially create two almost identical ones
stacked_df[2, -1] <- stacked_df[2, -1]*1.001
stacked_df[4, -1] <- stacked_df[4, -1]*1.001
stacked_df[6, -1] <- stacked_df[6, -1]*1.001
# Add expected population fractions (stemming from the mixing of both sources through sandbox)
stacked_df$Pop_fraction <- c(rep(frac_pop_1, 2), rep(frac_pop_2, 2), rep(frac_pop_3, 2), rep(NaN, 1))
print(stacked_df)
# Save the Data Frame
#filename <- paste0(as.character(pop_ratios_iteration[1]),"-", as.character(pop_ratios_iteration[2]),"-", as.character(pop_ratios_iteration[3]))
#write.csv(stacked_df, file = paste0(data_path, "/", filename, ".csv"))
